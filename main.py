import yt_dlp
from pydub import AudioSegment
import subprocess
import json
import os
import re
import trafilatura
import uuid
import requests
from duckduckgo_search import AsyncDDGS
from PyPDF2 import PdfReader
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import CommandHandler, MessageHandler, CallbackQueryHandler, filters, ApplicationBuilder


# å¾ç’°å¢ƒè®Šæ•¸ä¸­å–å¾— OpenAI API Key
openai_api_key = os.environ.get("OPENAI_API_KEY", "YOUR_API_KEY")
telegram_token = os.environ.get("TELEGRAM_TOKEN", "xxx")
model = os.environ.get("LLM_MODEL", "gpt-4o-mini")
lang = os.environ.get("TS_LANG", "ç¹é«”ä¸­æ–‡")
ddg_region = os.environ.get("DDG_REGION", "wt-wt")
chunk_size = int(os.environ.get("CHUNK_SIZE", 2100))
allowed_users = os.environ.get("ALLOWED_USERS", "")
use_audio_fallback = int(os.environ.get("USE_AUDIO_FALLBACK", "0"))
# æ·»åŠ  GROQ API Key
groq_api_key = os.environ.get("GROQ_API_KEY", "YOUR_GROQ_API_KEY")
base_url = os.environ.get("LLM_BASE_URL", "https://api.openai.com/v1")

def split_user_input(text):
    paragraphs = text.split('\n')
    paragraphs = [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]
    return paragraphs

def scrape_text_from_url(url):
    try:
        downloaded = trafilatura.fetch_url(url)
        text = trafilatura.extract(downloaded, include_formatting=True)
        if text is None:
            return []
        text_chunks = text.split("\n")
        article_content = [text for text in text_chunks if text]
        return article_content
    except Exception as e:
        print(f"Error: {e}")

async def search_results(keywords):
    print(keywords, ddg_region)
    results = await AsyncDDGS().text(keywords, region=ddg_region, safesearch='off', max_results=6)
    return results

def summarize(text_array):
    def create_chunks(paragraphs):
        chunks = []
        chunk = ''
        for paragraph in paragraphs:
            if len(chunk) + len(paragraph) < chunk_size:
                chunk += paragraph + ' '
            else:
                chunks.append(chunk.strip())
                chunk = paragraph + ' '
        if chunk:
            chunks.append(chunk.strip())
        return chunks

    try:
        text_chunks = create_chunks(text_array)
        text_chunks = [chunk for chunk in text_chunks if chunk]

        summaries = []
        system_messages = [
            {"role": "system", "content": "å°‡ä»¥ä¸‹åŸæ–‡ç¸½çµç‚ºäº”å€‹éƒ¨åˆ†ï¼š1.ç¸½çµ (Overall Summary)ã€‚2.è§€é» (Viewpoints)ã€‚3.æ‘˜è¦ (Abstract)ï¼š å‰µå»º6åˆ°10å€‹å¸¶æœ‰é©ç•¶è¡¨æƒ…ç¬¦è™Ÿçš„é‡é»æ‘˜è¦ã€‚4.é—œéµå­— (Key Words)ã€‚ 5.ä¸€å€‹è®“åäºŒæ­²é’å°‘å¹´å¯ä»¥çœ‹å¾—å‹•æ‡‚çš„æ®µè½ã€‚è«‹ç¢ºä¿æ¯å€‹éƒ¨åˆ†åªç”Ÿæˆä¸€æ¬¡ï¼Œä¸”å…§å®¹ä¸é‡è¤‡ã€‚ç¢ºä¿ç”Ÿæˆçš„æ–‡å­—éƒ½æ˜¯{lang}ç‚ºä¸»"}
        ]

        with ThreadPoolExecutor() as executor:
            futures = [executor.submit(call_gpt_api, f"ç¸½çµ the following text:\n{chunk}", system_messages) for chunk in text_chunks]
            summaries = [future.result() for future in tqdm(futures, total=len(text_chunks), desc="Summarizing")]

        final_summary = {
            "overall_summary": "",
            "viewpoints": "",
            "abstract": "",
            "keywords": ""
        }
        for summary in summaries:
            if 'ç¸½çµ (Overall Summary)' in summary and not final_summary["overall_summary"]:
                final_summary["overall_summary"] = summary.split('è§€é» (Viewpoints)')[0].strip()
            if 'è§€é» (Viewpoints)' in summary and not final_summary["viewpoints"]:
                content = summary.split('æ‘˜è¦ (Abstract)')[0].split('è§€é» (Viewpoints)')[1].strip()
                final_summary["viewpoints"] = content
            if 'æ‘˜è¦ (Abstract)' in summary and not final_summary["abstract"]:
                content = summary.split('é—œéµå­— (Key Words)')[0].split('æ‘˜è¦ (Abstract)')[1].strip()
                final_summary["abstract"] = content
            if 'é—œéµå­— (Key Words)' in summary and not final_summary["keywords"]:
                content = summary.split('é—œéµå­— (Key Words)')[1].strip()
                final_summary["keywords"] = content

        output = "\n\n".join([
            f" â‡£ \n\n{final_summary['overall_summary']}",
            f" ğ’¤ è§€é» (Viewpoints) ğ’¤\n{final_summary['viewpoints']}",
            f" ğ’¤ æ‘˜è¦ (Abstract) ğ’¤\n{final_summary['abstract']}",
            f" ğ’¤ é—œéµå­— (Key Words) ğ’¤\n{final_summary['keywords']}",
            f" â‡¡ \n",
            f" âœ¡ è¬è¬ä½¿ç”¨ Oli å°æ¿ƒç¸® (Summary) âœ¡ ",
        ])
        return output
    except Exception as e:
        print(f"Error: {e}")
        return "Unknown error! Please contact the owner. ok@vip.david888.com"

def extract_youtube_transcript(youtube_url):
    ydl_opts = {
        'writesubtitles': True,
        'writeautomaticsub': True,
        'skip_download': True,
        'subtitleslangs': ['zh-Hant', 'zh-Hans', 'zh-TW' , 'zh', 'en'],  # å„ªå…ˆé †åºï¼šç¹é«”ä¸­æ–‡ï¼Œç°¡é«”ä¸­æ–‡ï¼Œä¸­æ–‡ï¼Œè‹±æ–‡
        'outtmpl': '/tmp/%(id)s.%(ext)s',
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)
            if 'subtitles' in info or 'automatic_captions' in info:
                ydl.download([youtube_url])
                video_id = info['id']
                
                subtitle_content = None
                for lang in ['zh-Hant', 'zh-Hans', 'zh', 'en']:
                    subtitle_file = f"/tmp/{video_id}.{lang}.vtt"
                    if os.path.exists(subtitle_file):
                        with open(subtitle_file, 'r', encoding='utf-8') as file:
                            subtitle_content = file.read()
                        os.remove(subtitle_file)
                        print(f"Found and using {lang} subtitle.")
                        break  # æ‰¾åˆ°ç¬¬ä¸€å€‹å¯ç”¨çš„å­—å¹•å°±åœæ­¢

                # åˆªé™¤æ‰€æœ‰å‰©é¤˜çš„å­—å¹•æ–‡ä»¶
                for file in os.listdir('/tmp'):
                    if file.startswith(video_id) and file.endswith('.vtt'):
                        os.remove(f"/tmp/{file}")
                        print(f"Removed unused subtitle file: {file}")

                if subtitle_content:
                    return subtitle_content
                else:
                    print("No suitable subtitles found in specified languages.")
                    return "no transcript"
            else:
                print("No subtitles or automatic captions available for this video.")
                return "no transcript"
    except Exception as e:
        print(f"Error in extract_youtube_transcript: {e}")
        return "no transcript"



def retrieve_yt_transcript_from_url(youtube_url):
    try:
        subtitle_content = extract_youtube_transcript(youtube_url)
        if subtitle_content == "no transcript":
            if use_audio_fallback:
                print("No usable subtitles found. Falling back to audio transcription.")
                return audio_transcription(youtube_url)
            else:
                return ["è©²å½±ç‰‡æ²’æœ‰å¯ç”¨çš„å­—å¹•ï¼Œä¸”éŸ³é »è½‰æ›åŠŸèƒ½æœªå•Ÿç”¨ã€‚"]

        # æ¸…ç†å­—å¹•å…§å®¹
        cleaned_content = re.sub(r'WEBVTT\n\n', '', subtitle_content)
        cleaned_content = re.sub(r'\d+:\d+:\d+\.\d+ --> \d+:\d+:\d+\.\d+\n', '', cleaned_content)
        cleaned_content = re.sub(r'\n\n', ' ', cleaned_content)

        # å°‡æ¸…ç†å¾Œçš„å…§å®¹åˆ†å‰²æˆchunks
        output_chunks = []
        current_chunk = ""
        for word in cleaned_content.split():
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in retrieve_yt_transcript_from_url: {e}")
        return ["ç„¡æ³•ç²å–å­—å¹•æˆ–é€²è¡ŒéŸ³é »è½‰æ›ã€‚"]
    
def audio_transcription(youtube_url):
    try:
        # ä½¿ç”¨ yt-dlp ä¸‹è¼‰éŸ³é »
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'/tmp/{str(uuid.uuid4())}.%(ext)s',
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe'
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            output_path = ydl.prepare_filename(info)

        output_path = output_path.replace(os.path.splitext(output_path)[1], ".mp3")
        audio_file = AudioSegment.from_file(output_path)

        chunk_size = 100 * 1000  # 100 ç§’
        chunks = [audio_file[i:i+chunk_size] for i in range(0, len(audio_file), chunk_size)]

        transcript = ""
        for i, chunk in enumerate(chunks):
            temp_file_path = f"/tmp/{str(uuid.uuid4())}.wav"
            chunk.export(temp_file_path, format="wav")

            curl_command = [
                "curl",
                "https://api.groq.com/openai/v1/audio/transcriptions",
                "-H", f"Authorization: Bearer {os.environ.get('GROQ_API_KEY', 'YOUR_GROQ_API_KEY')}",
                "-H", "Content-Type: multipart/form-data",
                "-F", f"file=@{temp_file_path}",
                "-F", "model=whisper-large-v3"
            ]

            result = subprocess.run(curl_command, capture_output=True, text=True)

            try:
                response_json = json.loads(result.stdout)
                transcript += response_json["text"]
            except KeyError as e:
                print("KeyError:", e)
                print("Response JSON:", response_json)
            except json.JSONDecodeError:
                print("Failed to decode JSON:", result.stdout)

            os.remove(temp_file_path)  # åˆªé™¤è‡¨æ™‚éŸ³è¨Šæ–‡ä»¶

        os.remove(output_path)  # åˆªé™¤ä¸‹è¼‰çš„ mp3 æ–‡ä»¶

        # å°‡è½‰éŒ„æ–‡æœ¬åˆ†å‰²æˆ chunks
        output_sentences = transcript.split()
        output_chunks = []
        current_chunk = ""

        for word in output_sentences:
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in audio_transcription: {e}")
        return ["éŸ³é »è½‰éŒ„å¤±æ•—ã€‚"]    


def call_gpt_api(prompt, additional_messages=[]):
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }
    data = {
        "model": model,
        "messages": additional_messages + [
            {"role": "user", "content": prompt}
        ],
    }

    try:
        response = requests.post(f"{base_url}/chat/completions", headers=headers, json=data)
        response.raise_for_status()  # å¦‚æœè¿”å›é 200 çš„ç‹€æ…‹ç¢¼æœƒæ‹‹å‡ºç•°å¸¸
        message = response.json()["choices"][0]["message"]["content"].strip()
        return message
    except requests.exceptions.RequestException as e:
        print(f"Request error: {e}")
        return ""


async def handle_start(update, context):
    return await handle('start', update, context)

async def handle_help(update, context):
    return await handle('help', update, context)

async def handle_summarize(update, context):
    return await handle('summarize', update, context)

async def handle_file(update, context):
    return await handle('file', update, context)

# async def handle_button_click(update, context):
#     return await handle('button_click', update, context)
async def handle_button_click(update, context):
    query = update.callback_query
    await query.answer()

async def handle_yt2audio(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:  # æª¢æŸ¥æ˜¯å¦æœ‰æä¾› URL
        await context.bot.send_message(chat_id=chat_id, text="è«‹æä¾›ä¸€å€‹ YouTube å½±ç‰‡çš„ URLã€‚ä¾‹å¦‚ï¼š/yt2audio Youtubeçš„URL")
        return

    url = user_input[1]  # å–å¾— YouTube URL

    try:
        # ä½¿ç”¨ yt-dlp ä¸‹è¼‰éŸ³é »
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'/tmp/{str(uuid.uuid4())}.%(ext)s',  # ç›´æ¥ä½¿ç”¨é€™å€‹æ¨¡æ¿ä¾†ç”Ÿæˆæ–‡ä»¶å
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe'
        }


        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        # ä¸å†ä½¿ç”¨ replaceï¼Œç›´æ¥ä½¿ç”¨ä¸‹è¼‰å¾Œçš„æ–‡ä»¶
        output_path = ydl_opts['outtmpl']  # é€™è£¡æ˜¯å¸¶æœ‰ "%(ext)s" çš„æ¨¡æ¿

        # å¦‚æœä½ ç¢ºå®šå·²ç¶“ä¸‹è¼‰ç‚º .mp3ï¼Œå¯ä»¥ç›´æ¥ç”¨æ–‡ä»¶è·¯å¾‘
        output_path = output_path.replace("%(ext)s", "mp3")  # å¦‚æœä½ æƒ³ä¿ç•™é€™è¡Œä¹Ÿå¯ä»¥ï¼Œç¢ºä¿æ–‡ä»¶æ˜¯ mp3 æ ¼å¼

        audio_file = AudioSegment.from_file(output_path)        
 


            
        # å‚³é€éŸ³é »æª”æ¡ˆçµ¦ Telegram user
        with open(output_path, 'rb') as audio:
            await context.bot.send_audio(chat_id=chat_id, audio=audio)

        os.remove(output_path)  # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ       
  

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="ä¸‹è¼‰æˆ–å‚³é€éŸ³é »å¤±æ•—ã€‚è«‹æª¢æŸ¥è¼¸å…¥çš„ YouTube URL æ˜¯å¦æ­£ç¢ºã€‚")
        


async def handle_yt2text(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:
        await context.bot.send_message(chat_id=chat_id, text="è«‹æä¾›ä¸€å€‹ YouTube å½±ç‰‡çš„ URLã€‚ä¾‹å¦‚ï¼š/yt2text Youtubeçš„URL")
        return

    url = user_input[1]

    try:
        output_chunks = retrieve_yt_transcript_from_url(url)

        if len(output_chunks) == 1 and (output_chunks[0] == "è©²å½±ç‰‡æ²’æœ‰å¯ç”¨çš„å­—å¹•ã€‚" or output_chunks[0] == "ç„¡æ³•ç²å–å­—å¹•ï¼Œä¸”éŸ³é »è½‰æ›åŠŸèƒ½æœªå•Ÿç”¨ã€‚"):
            await context.bot.send_message(chat_id=chat_id, text=output_chunks[0])
            return

        # è™•ç†æ­£å¸¸æƒ…æ³çš„ä»£ç¢¼
        temp_file_path = f"/tmp/{str(uuid.uuid4())}.txt"
        with open(temp_file_path, 'w', encoding='utf-8') as file:
            for chunk in output_chunks:
                file.write(chunk + "\n")

        with open(temp_file_path, 'rb') as txt_file:
            await context.bot.send_document(chat_id=chat_id, document=txt_file, filename="transcript.txt")

        os.remove(temp_file_path)  # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="ä¸‹è¼‰æˆ–è½‰æ›æ–‡æœ¬å¤±æ•—ã€‚è«‹æª¢æŸ¥è¼¸å…¥çš„ YouTube URL æ˜¯å¦æ­£ç¢ºã€‚")

        
def process_user_input(user_input):
    youtube_pattern = re.compile(r"https?://(www\.|m\.)?(youtube\.com|youtu\.be)/")
    url_pattern = re.compile(r"https?://")

    if youtube_pattern.match(user_input):
        text_array = retrieve_yt_transcript_from_url(user_input)
    elif url_pattern.match(user_input):
        text_array = scrape_text_from_url(user_input)
    else:
        text_array = split_user_input(user_input)

    return text_array

def get_inline_keyboard_buttons(summary_text):
    encoded_text = requests.utils.quote(summary_text)
    twitter_url = f"https://twitter.com/intent/tweet?text={encoded_text}"

    keyboard = [
        [InlineKeyboardButton("Share to Twitter", url=twitter_url)],
    ]
    return InlineKeyboardMarkup(keyboard)

def clear_old_commands(telegram_token):
    url = f"https://api.telegram.org/bot{telegram_token}/deleteMyCommands"
    
    scopes = ["default", "all_private_chats", "all_group_chats", "all_chat_administrators"]
    
    for scope in scopes:
        data = {"scope": {"type": scope}}
        response = requests.post(url, json=data)
        
        if response.status_code == 200:
            print(f"Old commands cleared successfully for scope: {scope}")
        else:
            print(f"Failed to clear old commands for scope {scope}: {response.text}")

def set_my_commands(telegram_token):
    clear_old_commands(telegram_token)  # æ¸…é™¤èˆŠçš„å‘½ä»¤
    url = f"https://api.telegram.org/bot{telegram_token}/setMyCommands"
    commands = [
        {"command": "start", "description": "ç¢ºèªæ©Ÿå™¨äººæ˜¯å¦åœ¨ç·š"},
        {"command": "help", "description": "é¡¯ç¤ºæ­¤å¹«åŠ©è¨Šæ¯"},
        {"command": "yt2audio", "description": "ä¸‹è¼‰ YouTube éŸ³é »"},
        {"command": "yt2text", "description": "å°‡ YouTube å½±ç‰‡è½‰æˆæ–‡å­—"},
    ]
    data = {"commands": commands}
    response = requests.post(url, json=data)

    if response.status_code == 200:
        print("Commands set successfully.")
    else:
        print(f"Failed to set commands: {response.text}")
        
async def handle(action, update, context):
    chat_id = update.effective_chat.id
    user_id = update.effective_user.id

    if allowed_users and str(user_id) not in allowed_users.split(','):
        await context.bot.send_message(chat_id=chat_id, text="Sorry, you are not authorized to use this bot.")
        return

    if action == 'start':
        await context.bot.send_message(chat_id=chat_id, text="æˆ‘æ˜¯æ±Ÿå®¶æ©Ÿå™¨äººä¹‹ä¸€ã€‚ç‰ˆæœ¬20240828ã€‚ è«‹ç›´æ¥è¼¸å…¥ URL æˆ–æƒ³è¦ç¸½çµçš„æ–‡å­—æˆ–PDFï¼Œç„¡è«–æ˜¯ä½•ç¨®èªè¨€ï¼Œæˆ‘éƒ½æœƒå¹«ä½ è‡ªå‹•ç¸½çµç‚ºä¸­æ–‡çš„å…§å®¹ã€‚ç›®å‰ URL åƒ…æ”¯æ´å…¬é–‹æ–‡ç« èˆ‡ YouTube ç­‰ç¶²å€ï¼Œå°šæœªæ”¯æ´ Facebook èˆ‡ Twitter è²¼æ–‡ï¼ŒYouTube çš„ç›´æ’­å½±ç‰‡ã€ç§äººå½±ç‰‡èˆ‡æœƒå“¡å°ˆå±¬å½±ç‰‡ä¹Ÿç„¡æ³•ç¸½çµå–”ã€‚å¦‚è¦ç¸½çµ YouTube å½±ç‰‡ï¼Œè«‹å‹™å¿…ä¸€æ¬¡è¼¸å…¥ä¸€å€‹ç¶²å€ï¼Œä¹Ÿä¸è¦å¯«å­—ï¼Œå‚³ç¶²å€å°±å¥½ã€‚æé†’ï¼šæˆ‘ç„¡æ³•èŠå¤©ï¼Œæ‰€ä»¥ä¸è¦å•æˆ‘å•é¡Œï¼Œæˆ‘åªèƒ½ç¸½çµæ–‡ç« æˆ–å½±ç‰‡å­—å¹•ã€‚ I'm here to help you summarize text and YouTube videos.")
    elif action == 'help':
        help_text = """
        I can summarize text, URLs, PDFs and YouTube video for you.è«‹ç›´æ¥è¼¸å…¥ URL æˆ–æƒ³è¦ç¸½çµçš„æ–‡å­—æˆ–PDFï¼Œç„¡è«–æ˜¯ä½•ç¨®èªè¨€ï¼Œæˆ‘éƒ½æœƒå¹«ä½ è‡ªå‹•ç¸½çµç‚ºä¸­æ–‡çš„å…§å®¹ã€‚ç›®å‰ URL åƒ…æ”¯æ´å…¬é–‹æ–‡ç« èˆ‡ YouTube ç­‰ç¶²å€ï¼Œå°šæœªæ”¯æ´ Facebook èˆ‡ Twitter è²¼æ–‡ï¼ŒYouTube çš„ç›´æ’­å½±ç‰‡ã€ç§äººå½±ç‰‡èˆ‡æœƒå“¡å°ˆå±¬å½±ç‰‡ä¹Ÿç„¡æ³•ç¸½çµå–”ã€‚å¦‚è¦ç¸½çµ YouTube å½±ç‰‡ï¼Œè«‹å‹™å¿…ä¸€æ¬¡è¼¸å…¥ä¸€å€‹ç¶²å€ï¼Œä¹Ÿä¸è¦å¯«å­—ï¼Œå‚³ç¶²å€å°±å¥½ã€‚æé†’ï¼šæˆ‘ç„¡æ³•èŠå¤©ï¼Œæ‰€ä»¥ä¸è¦å•æˆ‘å•é¡Œï¼Œæˆ‘åªèƒ½ç¸½çµæ–‡ç« æˆ–å½±ç‰‡å­—å¹•ã€‚        
        Here are the available commands:
        /start - Start the bot
        /help - Show this help message
        /yt2audio <YouTube URL> - Download YouTube audio
        /yt2text <YouTube URL> - Convert YouTube video to text
        
        You can also send me any text or URL to summarize.
        """
        await context.bot.send_message(chat_id=chat_id, text=help_text)
    elif action == 'summarize':
        user_input = update.message.text
        text_array = process_user_input(user_input)
        if text_array:
            summary = summarize(text_array)
            original_url = user_input  # å‡è¨­ç”¨æˆ¶è¼¸å…¥çš„æ˜¯URL
            summary_with_original = f"{summary}\n\n[Original]({original_url})"  # å°‡åŸå§‹URLé™„åŠ åˆ°ç¸½çµå¾Œ
            await context.bot.send_message(chat_id=chat_id, text=summary_with_original, reply_markup=get_inline_keyboard_buttons(summary_with_original))
            # await context.bot.send_message(chat_id=chat_id, text=summary, reply_markup=get_inline_keyboard_buttons(summary))
        else:
            await context.bot.send_message(chat_id=chat_id, text="Sorry, I couldn't process your input. Please try again.")
    elif action == 'file':
        file = await update.message.document.get_file()
        file_path = f"/tmp/{file.file_id}.pdf"
        await file.download_to_drive(file_path)
        
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        
        os.remove(file_path)
        
        text_array = text.split("\n")
        summary = summarize(text_array)
        await context.bot.send_message(chat_id=chat_id, text=summary, reply_markup=get_inline_keyboard_buttons(summary))
    elif action == 'button_click':
        query = update.callback_query
        await query.answer()
        
        if query.data == 'explore_similar':
            await context.bot.send_message(chat_id=chat_id, text="Here are some similar topics...")
        elif query.data == 'why_it_matters':
            await context.bot.send_message(chat_id=chat_id, text="This topic matters because...")
            

def main():
    try:
        application = ApplicationBuilder().token(telegram_token).build()
        start_handler = CommandHandler('start', handle_start)
        help_handler = CommandHandler('help', handle_help)
        yt2audio_handler = CommandHandler('yt2audio', handle_yt2audio)
        yt2text_handler = CommandHandler('yt2text', handle_yt2text)
        set_my_commands(telegram_token)
        summarize_handler = MessageHandler(filters.TEXT & ~filters.COMMAND, handle_summarize)
        file_handler = MessageHandler(filters.Document.PDF, handle_file)
        button_click_handler = CallbackQueryHandler(handle_button_click)
        application.add_handler(file_handler)
        application.add_handler(start_handler)
        application.add_handler(help_handler)
        application.add_handler(yt2audio_handler)
        application.add_handler(yt2text_handler)
        application.add_handler(summarize_handler)
        application.add_handler(button_click_handler)
        application.run_polling()
    except Exception as e:
        print(e)

if __name__ == '__main__':
    main()
