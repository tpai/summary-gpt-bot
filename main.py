import yt_dlp
from pydub import AudioSegment
import subprocess
import json
import os
import re
import trafilatura
import uuid
import requests
from duckduckgo_search import AsyncDDGS
from PyPDF2 import PdfReader
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import CommandHandler, MessageHandler, CallbackQueryHandler, filters, ApplicationBuilder


# ÂæûÁí∞Â¢ÉËÆäÊï∏‰∏≠ÂèñÂæó OpenAI API Key
openai_api_key = os.environ.get("OPENAI_API_KEY", "YOUR_API_KEY")
telegram_token = os.environ.get("TELEGRAM_TOKEN", "xxx")
model = os.environ.get("LLM_MODEL", "gpt-4o-mini")
lang = os.environ.get("TS_LANG", "ÁπÅÈ´î‰∏≠Êñá")
ddg_region = os.environ.get("DDG_REGION", "wt-wt")
chunk_size = int(os.environ.get("CHUNK_SIZE", 2100))
allowed_users = os.environ.get("ALLOWED_USERS", "")
use_audio_fallback = int(os.environ.get("USE_AUDIO_FALLBACK", "0"))
# Ê∑ªÂä† GROQ API Key
groq_api_key = os.environ.get("GROQ_API_KEY", "YOUR_GROQ_API_KEY")
base_url = os.environ.get("LLM_BASE_URL", "https://api.openai.com/v1")

def split_user_input(text):
    paragraphs = text.split('\n')
    paragraphs = [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]
    return paragraphs

def scrape_text_from_url(url):
    try:
        downloaded = trafilatura.fetch_url(url)
        text = trafilatura.extract(downloaded, include_formatting=True)
        if text is None:
            return []
        text_chunks = text.split("\n")
        article_content = [text for text in text_chunks if text]
        return article_content
    except Exception as e:
        print(f"Error: {e}")

async def search_results(keywords):
    print(keywords, ddg_region)
    results = await AsyncDDGS().text(keywords, region=ddg_region, safesearch='off', max_results=6)
    return results

def summarize(text_array):
    def create_chunks(paragraphs):
        chunks = []
        chunk = ''
        for paragraph in paragraphs:
            if len(chunk) + len(paragraph) < chunk_size:
                chunk += paragraph + ' '
            else:
                chunks.append(chunk.strip())
                chunk = paragraph + ' '
        if chunk:
            chunks.append(chunk.strip())
        return chunks

    try:
        text_chunks = create_chunks(text_array)
        text_chunks = [chunk for chunk in text_chunks if chunk]

        summaries = []
        system_messages = [
            {"role": "system", "content": "Â∞á‰ª•‰∏ãÂéüÊñáÁ∏ΩÁµêÁÇ∫‰∫îÂÄãÈÉ®ÂàÜÔºö1.Á∏ΩÁµê (Overall Summary)„ÄÇ2.ËßÄÈªû (Viewpoints)„ÄÇ3.ÊëòË¶Å (Abstract)Ôºö ÂâµÂª∫6Âà∞10ÂÄãÂ∏∂ÊúâÈÅ©Áï∂Ë°®ÊÉÖÁ¨¶ËôüÁöÑÈáçÈªûÊëòË¶Å„ÄÇ4.ÈóúÈçµÂ≠ó (Key Words)„ÄÇ 5.‰∏ÄÂÄãËÆìÂçÅ‰∫åÊ≠≤ÈùíÂ∞ëÂπ¥ÂèØ‰ª•ÁúãÂæóÂãïÊáÇÁöÑÊÆµËêΩ„ÄÇË´ãÁ¢∫‰øùÊØèÂÄãÈÉ®ÂàÜÂè™ÁîüÊàê‰∏ÄÊ¨°Ôºå‰∏îÂÖßÂÆπ‰∏çÈáçË§á„ÄÇÁ¢∫‰øùÁîüÊàêÁöÑÊñáÂ≠óÈÉΩÊòØ{lang}ÁÇ∫‰∏ª"}
        ]

        with ThreadPoolExecutor() as executor:
            futures = [executor.submit(call_gpt_api, f"Á∏ΩÁµê the following text:\n{chunk}", system_messages) for chunk in text_chunks]
            summaries = [future.result() for future in tqdm(futures, total=len(text_chunks), desc="Summarizing")]

        final_summary = {
            "overall_summary": "",
            "viewpoints": "",
            "abstract": "",
            "keywords": ""
        }
        for summary in summaries:
            if 'Á∏ΩÁµê (Overall Summary)' in summary and not final_summary["overall_summary"]:
                final_summary["overall_summary"] = summary.split('ËßÄÈªû (Viewpoints)')[0].strip()
            if 'ËßÄÈªû (Viewpoints)' in summary and not final_summary["viewpoints"]:
                content = summary.split('ÊëòË¶Å (Abstract)')[0].split('ËßÄÈªû (Viewpoints)')[1].strip()
                final_summary["viewpoints"] = content
            if 'ÊëòË¶Å (Abstract)' in summary and not final_summary["abstract"]:
                content = summary.split('ÈóúÈçµÂ≠ó (Key Words)')[0].split('ÊëòË¶Å (Abstract)')[1].strip()
                final_summary["abstract"] = content
            if 'ÈóúÈçµÂ≠ó (Key Words)' in summary and not final_summary["keywords"]:
                content = summary.split('ÈóúÈçµÂ≠ó (Key Words)')[1].strip()
                final_summary["keywords"] = content

        output = "\n\n".join([
            f" ‚á£ \n\n{final_summary['overall_summary']}",
            f" íê§ ËßÄÈªû (Viewpoints) íê§\n{final_summary['viewpoints']}",
            f" íê§ ÊëòË¶Å (Abstract) íê§\n{final_summary['abstract']}",
            f" íê§ ÈóúÈçµÂ≠ó (Key Words) íê§\n{final_summary['keywords']}",
            f" ‚á° \n",
            f" ‚ú° Ë¨ùË¨ù‰ΩøÁî® Oli Â∞èÊøÉÁ∏Æ (Summary) ‚ú° ",
        ])
        return output
    except Exception as e:
        print(f"Error: {e}")
        return "Unknown error! Please contact the owner. ok@vip.david888.com"

def extract_youtube_transcript(youtube_url):
    ydl_opts = {
        'writesubtitles': True,
        'writeautomaticsub': True,
        'skip_download': True,
        'subtitleslangs': ['zh-Hant', 'zh-Hans', 'zh-TW' , 'zh', 'en'],  # ÂÑ™ÂÖàÈ†ÜÂ∫èÔºöÁπÅÈ´î‰∏≠ÊñáÔºåÁ∞°È´î‰∏≠ÊñáÔºå‰∏≠ÊñáÔºåËã±Êñá
        'outtmpl': '/tmp/%(id)s.%(ext)s',
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)
            if 'subtitles' in info or 'automatic_captions' in info:
                ydl.download([youtube_url])
                video_id = info['id']
                
                subtitle_content = None
                for lang in ['zh-Hant', 'zh-Hans', 'zh', 'en']:
                    subtitle_file = f"/tmp/{video_id}.{lang}.vtt"
                    if os.path.exists(subtitle_file):
                        with open(subtitle_file, 'r', encoding='utf-8') as file:
                            subtitle_content = file.read()
                        os.remove(subtitle_file)
                        print(f"Found and using {lang} subtitle.")
                        break  # ÊâæÂà∞Á¨¨‰∏ÄÂÄãÂèØÁî®ÁöÑÂ≠óÂπïÂ∞±ÂÅúÊ≠¢

                # Âà™Èô§ÊâÄÊúâÂâ©È§òÁöÑÂ≠óÂπïÊñá‰ª∂
                for file in os.listdir('/tmp'):
                    if file.startswith(video_id) and file.endswith('.vtt'):
                        os.remove(f"/tmp/{file}")
                        print(f"Removed unused subtitle file: {file}")

                if subtitle_content:
                    return subtitle_content
                else:
                    print("No suitable subtitles found in specified languages.")
                    return "no transcript"
            else:
                print("No subtitles or automatic captions available for this video.")
                return "no transcript"
    except Exception as e:
        print(f"Error in extract_youtube_transcript: {e}")
        return "no transcript"



def retrieve_yt_transcript_from_url(youtube_url):
    try:
        subtitle_content = extract_youtube_transcript(youtube_url)
        if subtitle_content == "no transcript":
            if use_audio_fallback:
                print("No usable subtitles found. Falling back to audio transcription.")
                return audio_transcription(youtube_url)
            else:
                return ["Ë©≤ÂΩ±ÁâáÊ≤íÊúâÂèØÁî®ÁöÑÂ≠óÂπïÔºå‰∏îÈü≥È†ªËΩâÊèõÂäüËÉΩÊú™ÂïüÁî®„ÄÇ"]

        # Ê∏ÖÁêÜÂ≠óÂπïÂÖßÂÆπ
        cleaned_content = re.sub(r'WEBVTT\n\n', '', subtitle_content)
        cleaned_content = re.sub(r'\d+:\d+:\d+\.\d+ --> \d+:\d+:\d+\.\d+\n', '', cleaned_content)
        cleaned_content = re.sub(r'\n\n', ' ', cleaned_content)

        # Â∞áÊ∏ÖÁêÜÂæåÁöÑÂÖßÂÆπÂàÜÂâ≤Êàêchunks
        output_chunks = []
        current_chunk = ""
        for word in cleaned_content.split():
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in retrieve_yt_transcript_from_url: {e}")
        return ["ÁÑ°Ê≥ïÁç≤ÂèñÂ≠óÂπïÊàñÈÄ≤Ë°åÈü≥È†ªËΩâÊèõ„ÄÇ"]
    
def audio_transcription(youtube_url):
    try:
        # ‰ΩøÁî® yt-dlp ‰∏ãËºâÈü≥È†ª
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'/tmp/{str(uuid.uuid4())}.%(ext)s',
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe'
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            output_path = ydl.prepare_filename(info)

        output_path = output_path.replace(os.path.splitext(output_path)[1], ".mp3")
        audio_file = AudioSegment.from_file(output_path)

        chunk_size = 100 * 1000  # 100 Áßí
        chunks = [audio_file[i:i+chunk_size] for i in range(0, len(audio_file), chunk_size)]

        transcript = ""
        for i, chunk in enumerate(chunks):
            temp_file_path = f"/tmp/{str(uuid.uuid4())}.wav"
            chunk.export(temp_file_path, format="wav")

            curl_command = [
                "curl",
                "https://api.groq.com/openai/v1/audio/transcriptions",
                "-H", f"Authorization: Bearer {os.environ.get('GROQ_API_KEY', 'YOUR_GROQ_API_KEY')}",
                "-H", "Content-Type: multipart/form-data",
                "-F", f"file=@{temp_file_path}",
                "-F", "model=whisper-large-v3"
            ]

            result = subprocess.run(curl_command, capture_output=True, text=True)

            try:
                response_json = json.loads(result.stdout)
                transcript += response_json["text"]
            except KeyError as e:
                print("KeyError:", e)
                print("Response JSON:", response_json)
            except json.JSONDecodeError:
                print("Failed to decode JSON:", result.stdout)

            os.remove(temp_file_path)  # Âà†Èô§‰∏¥Êó∂Èü≥È¢ëÊñá‰ª∂

        os.remove(output_path)  # Âà†Èô§‰∏ãËΩΩÁöÑ mp3 Êñá‰ª∂

        # Â∞ÜËΩ¨ÂΩïÊñáÊú¨ÂàÜÂâ≤Êàê chunks
        output_sentences = transcript.split()
        output_chunks = []
        current_chunk = ""

        for word in output_sentences:
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in audio_transcription: {e}")
        return ["Èü≥È†ªËΩâÈåÑÂ§±Êïó„ÄÇ"]    


def call_gpt_api(prompt, additional_messages=[]):
    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json",
    }
    data = {
        "model": model,
        "messages": additional_messages + [
            {"role": "user", "content": prompt}
        ],
    }

    try:
        response = requests.post(f"{base_url}/chat/completions", headers=headers, json=data)
        response.raise_for_status()  # Â¶ÇÊûúËøîÂõûÈùû 200 ÁöÑÁãÄÊÖãÁ¢ºÊúÉÊããÂá∫Áï∞Â∏∏
        message = response.json()["choices"][0]["message"]["content"].strip()
        return message
    except requests.exceptions.RequestException as e:
        print(f"Request error: {e}")
        return ""


async def handle_start(update, context):
    return await handle('start', update, context)

async def handle_help(update, context):
    return await handle('help', update, context)

async def handle_summarize(update, context):
    return await handle('summarize', update, context)

async def handle_file(update, context):
    return await handle('file', update, context)

async def handle_button_click(update, context):
    return await handle('button_click', update, context)


async def handle_yt2audio(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:  # Ê™¢Êü•ÊòØÂê¶ÊúâÊèê‰æõ URL
        await context.bot.send_message(chat_id=chat_id, text="Ë´ãÊèê‰æõ‰∏ÄÂÄã YouTube ÂΩ±ÁâáÁöÑ URL„ÄÇ‰æãÂ¶ÇÔºö/yt2audio YoutubeÁöÑURL")
        return

    url = user_input[1]  # ÂèñÂæó YouTube URL

    try:
        # ‰ΩøÁî® yt-dlp ‰∏ãËºâÈü≥È†ª
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'/tmp/{str(uuid.uuid4())}.%(ext)s',  # Áõ¥Êé•‰ΩøÁî®ÈÄôÂÄãÊ®°Êùø‰æÜÁîüÊàêÊñá‰ª∂Âêç
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe'
        }


        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        # ‰∏çÂÜç‰ΩøÁî® replaceÔºåÁõ¥Êé•‰ΩøÁî®‰∏ãËºâÂæåÁöÑÊñá‰ª∂
        output_path = ydl_opts['outtmpl']  # ÈÄôË£°ÊòØÂ∏∂Êúâ "%(ext)s" ÁöÑÊ®°Êùø

        # Â¶ÇÊûú‰Ω†Á¢∫ÂÆöÂ∑≤Á∂ì‰∏ãËºâÁÇ∫ .mp3ÔºåÂèØ‰ª•Áõ¥Êé•Áî®Êñá‰ª∂Ë∑ØÂæë
        output_path = output_path.replace("%(ext)s", "mp3")  # Â¶ÇÊûú‰Ω†ÊÉ≥‰øùÁïôÈÄôË°å‰πüÂèØ‰ª•ÔºåÁ¢∫‰øùÊñá‰ª∂ÊòØ mp3 Ê†ºÂºè

        audio_file = AudioSegment.from_file(output_path)        
 


            
        # ÂÇ≥ÈÄÅÈü≥È†ªÊ™îÊ°àÁµ¶ Telegram user
        with open(output_path, 'rb') as audio:
            await context.bot.send_audio(chat_id=chat_id, audio=audio)

        os.remove(output_path)  # Âà™Èô§Ëá®ÊôÇÊ™îÊ°à       
  

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="‰∏ãËºâÊàñÂÇ≥ÈÄÅÈü≥È†ªÂ§±Êïó„ÄÇË´ãÊ™¢Êü•Ëº∏ÂÖ•ÁöÑ YouTube URL ÊòØÂê¶Ê≠£Á¢∫„ÄÇ")
        


async def handle_yt2text(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:
        await context.bot.send_message(chat_id=chat_id, text="Ë´ãÊèê‰æõ‰∏ÄÂÄã YouTube ÂΩ±ÁâáÁöÑ URL„ÄÇ‰æãÂ¶ÇÔºö/yt2text YoutubeÁöÑURL")
        return

    url = user_input[1]

    try:
        output_chunks = retrieve_yt_transcript_from_url(url)

        if len(output_chunks) == 1 and (output_chunks[0] == "Ë©≤ÂΩ±ÁâáÊ≤íÊúâÂèØÁî®ÁöÑÂ≠óÂπï„ÄÇ" or output_chunks[0] == "ÁÑ°Ê≥ïÁç≤ÂèñÂ≠óÂπïÔºå‰∏îÈü≥È†ªËΩâÊèõÂäüËÉΩÊú™ÂïüÁî®„ÄÇ"):
            await context.bot.send_message(chat_id=chat_id, text=output_chunks[0])
            return

        # ËôïÁêÜÊ≠£Â∏∏ÊÉÖÊ≥ÅÁöÑ‰ª£Á¢º
        temp_file_path = f"/tmp/{str(uuid.uuid4())}.txt"
        with open(temp_file_path, 'w', encoding='utf-8') as file:
            for chunk in output_chunks:
                file.write(chunk + "\n")

        with open(temp_file_path, 'rb') as txt_file:
            await context.bot.send_document(chat_id=chat_id, document=txt_file, filename="transcript.txt")

        os.remove(temp_file_path)  # Âà™Èô§Ëá®ÊôÇÊ™îÊ°à

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="‰∏ãËºâÊàñËΩâÊèõÊñáÊú¨Â§±Êïó„ÄÇË´ãÊ™¢Êü•Ëº∏ÂÖ•ÁöÑ YouTube URL ÊòØÂê¶Ê≠£Á¢∫„ÄÇ")

        
def process_user_input(user_input):
    youtube_pattern = re.compile(r"https?://(www\.|m\.)?(youtube\.com|youtu\.be)/")
    url_pattern = re.compile(r"https?://")

    if youtube_pattern.match(user_input):
        text_array = retrieve_yt_transcript_from_url(user_input)
    elif url_pattern.match(user_input):
        text_array = scrape_text_from_url(user_input)
    else:
        text_array = split_user_input(user_input)

    return text_array

def get_inline_keyboard_buttons():
    keyboard = [
        [InlineKeyboardButton("Explore Similar", callback_data="explore_similar")],
        [InlineKeyboardButton("Why It Matters", callback_data="why_it_matters")],
    ]
    return InlineKeyboardMarkup(keyboard)

def clear_old_commands(telegram_token):
    url = f"https://api.telegram.org/bot{telegram_token}/deleteMyCommands"
    
    scopes = ["default", "all_private_chats", "all_group_chats", "all_chat_administrators"]
    
    for scope in scopes:
        data = {"scope": {"type": scope}}
        response = requests.post(url, json=data)
        
        if response.status_code == 200:
            print(f"Old commands cleared successfully for scope: {scope}")
        else:
            print(f"Failed to clear old commands for scope {scope}: {response.text}")

def set_my_commands(telegram_token):
    clear_old_commands(telegram_token)  # Ê∏ÖÈô§ËàäÁöÑÂëΩ‰ª§
    url = f"https://api.telegram.org/bot{telegram_token}/setMyCommands"
    commands = [
        {"command": "start", "description": "Á¢∫Ë™çÊ©üÂô®‰∫∫ÊòØÂê¶Âú®Á∑ö"},
        {"command": "help", "description": "È°ØÁ§∫Ê≠§Âπ´Âä©Ë®äÊÅØ"},
        {"command": "yt2audio", "description": "‰∏ãËºâ YouTube Èü≥È†ª"},
        {"command": "yt2text", "description": "Â∞á YouTube ÂΩ±ÁâáËΩâÊàêÊñáÂ≠ó"},
    ]
    data = {"commands": commands}
    response = requests.post(url, json=data)

    if response.status_code == 200:
        print("Commands set successfully.")
    else:
        print(f"Failed to set commands: {response.text}")
        
async def handle(action, update, context):
    chat_id = update.effective_chat.id
    user_id = update.effective_user.id

    if allowed_users and str(user_id) not in allowed_users.split(','):
        await context.bot.send_message(chat_id=chat_id, text="Sorry, you are not authorized to use this bot.")
        return

    if action == 'start':
        await context.bot.send_message(chat_id=chat_id, text="ÊàëÊòØÊ±üÂÆ∂Ê©üÂô®‰∫∫‰πã‰∏Ä„ÄÇÁâàÊú¨20240828„ÄÇ Ë´ãÁõ¥Êé•Ëº∏ÂÖ• URL ÊàñÊÉ≥Ë¶ÅÁ∏ΩÁµêÁöÑÊñáÂ≠óÊàñPDFÔºåÁÑ°Ë´ñÊòØ‰ΩïÁ®ÆË™ûË®ÄÔºåÊàëÈÉΩÊúÉÂπ´‰Ω†Ëá™ÂãïÁ∏ΩÁµêÁÇ∫‰∏≠ÊñáÁöÑÂÖßÂÆπ„ÄÇÁõÆÂâç URL ÂÉÖÊîØÊè¥ÂÖ¨ÈñãÊñáÁ´†Ëàá YouTube Á≠âÁ∂≤ÂùÄÔºåÂ∞öÊú™ÊîØÊè¥ Facebook Ëàá Twitter Ë≤ºÊñáÔºåYouTube ÁöÑÁõ¥Êí≠ÂΩ±Áâá„ÄÅÁßÅ‰∫∫ÂΩ±ÁâáËàáÊúÉÂì°Â∞àÂ±¨ÂΩ±Áâá‰πüÁÑ°Ê≥ïÁ∏ΩÁµêÂñî„ÄÇÂ¶ÇË¶ÅÁ∏ΩÁµê YouTube ÂΩ±ÁâáÔºåË´ãÂãôÂøÖ‰∏ÄÊ¨°Ëº∏ÂÖ•‰∏ÄÂÄãÁ∂≤ÂùÄÔºå‰πü‰∏çË¶ÅÂØ´Â≠óÔºåÂÇ≥Á∂≤ÂùÄÂ∞±Â•Ω„ÄÇÊèêÈÜíÔºöÊàëÁÑ°Ê≥ïËÅäÂ§©ÔºåÊâÄ‰ª•‰∏çË¶ÅÂïèÊàëÂïèÈ°åÔºåÊàëÂè™ËÉΩÁ∏ΩÁµêÊñáÁ´†ÊàñÂΩ±ÁâáÂ≠óÂπï„ÄÇ I'm here to help you summarize text and YouTube videos.")
    elif action == 'help':
        help_text = """
        I can summarize text, URLs, PDFs and YouTube video for you.Ë´ãÁõ¥Êé•Ëº∏ÂÖ• URL ÊàñÊÉ≥Ë¶ÅÁ∏ΩÁµêÁöÑÊñáÂ≠óÊàñPDFÔºåÁÑ°Ë´ñÊòØ‰ΩïÁ®ÆË™ûË®ÄÔºåÊàëÈÉΩÊúÉÂπ´‰Ω†Ëá™ÂãïÁ∏ΩÁµêÁÇ∫‰∏≠ÊñáÁöÑÂÖßÂÆπ„ÄÇÁõÆÂâç URL ÂÉÖÊîØÊè¥ÂÖ¨ÈñãÊñáÁ´†Ëàá YouTube Á≠âÁ∂≤ÂùÄÔºåÂ∞öÊú™ÊîØÊè¥ Facebook Ëàá Twitter Ë≤ºÊñáÔºåYouTube ÁöÑÁõ¥Êí≠ÂΩ±Áâá„ÄÅÁßÅ‰∫∫ÂΩ±ÁâáËàáÊúÉÂì°Â∞àÂ±¨ÂΩ±Áâá‰πüÁÑ°Ê≥ïÁ∏ΩÁµêÂñî„ÄÇÂ¶ÇË¶ÅÁ∏ΩÁµê YouTube ÂΩ±ÁâáÔºåË´ãÂãôÂøÖ‰∏ÄÊ¨°Ëº∏ÂÖ•‰∏ÄÂÄãÁ∂≤ÂùÄÔºå‰πü‰∏çË¶ÅÂØ´Â≠óÔºåÂÇ≥Á∂≤ÂùÄÂ∞±Â•Ω„ÄÇÊèêÈÜíÔºöÊàëÁÑ°Ê≥ïËÅäÂ§©ÔºåÊâÄ‰ª•‰∏çË¶ÅÂïèÊàëÂïèÈ°åÔºåÊàëÂè™ËÉΩÁ∏ΩÁµêÊñáÁ´†ÊàñÂΩ±ÁâáÂ≠óÂπï„ÄÇ        
        Here are the available commands:
        /start - Start the bot
        /help - Show this help message
        /yt2audio <YouTube URL> - Download YouTube audio
        /yt2text <YouTube URL> - Convert YouTube video to text
        
        You can also send me any text or URL to summarize.
        """
        await context.bot.send_message(chat_id=chat_id, text=help_text)
    elif action == 'summarize':
        user_input = update.message.text
        text_array = process_user_input(user_input)
        if text_array:
            summary = summarize(text_array)
            await context.bot.send_message(chat_id=chat_id, text=summary, reply_markup=get_inline_keyboard_buttons())
        else:
            await context.bot.send_message(chat_id=chat_id, text="Sorry, I couldn't process your input. Please try again.")
    elif action == 'file':
        file = await update.message.document.get_file()
        file_path = f"/tmp/{file.file_id}.pdf"
        await file.download_to_drive(file_path)
        
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        
        os.remove(file_path)
        
        text_array = text.split("\n")
        summary = summarize(text_array)
        await context.bot.send_message(chat_id=chat_id, text=summary, reply_markup=get_inline_keyboard_buttons())
    elif action == 'button_click':
        query = update.callback_query
        await query.answer()
        
        if query.data == 'explore_similar':
            await context.bot.send_message(chat_id=chat_id, text="Here are some similar topics...")
        elif query.data == 'why_it_matters':
            await context.bot.send_message(chat_id=chat_id, text="This topic matters because...")



def main():
    try:
        application = ApplicationBuilder().token(telegram_token).build()
        start_handler = CommandHandler('start', handle_start)
        help_handler = CommandHandler('help', handle_help)
        yt2audio_handler = CommandHandler('yt2audio', handle_yt2audio)
        yt2text_handler = CommandHandler('yt2text', handle_yt2text)
        set_my_commands(telegram_token)
        summarize_handler = MessageHandler(filters.TEXT & ~filters.COMMAND, handle_summarize)
        file_handler = MessageHandler(filters.Document.PDF, handle_file)
        button_click_handler = CallbackQueryHandler(handle_button_click)
        application.add_handler(file_handler)
        application.add_handler(start_handler)
        application.add_handler(help_handler)
        application.add_handler(yt2audio_handler)
        application.add_handler(yt2text_handler)
        application.add_handler(summarize_handler)
        application.add_handler(button_click_handler)
        application.run_polling()
    except Exception as e:
        print(e)

if __name__ == '__main__':
    main()

